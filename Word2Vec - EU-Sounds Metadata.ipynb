{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-11-11T13:42:54.754Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import unicodedata\n",
    "\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:30.743000",
     "start_time": "2016-11-02T11:12:24.712000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "md = pd.read_pickle(\"E:/Data/MIR/EU_SOUNDS_FEATURES/combined_metadata.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:30.764000",
     "start_time": "2016-11-02T11:12:30.745000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#allsound; 400615                       http://econnect.ait.co.at/...\n",
       "index                                                          236221\n",
       "title                                              San José De Flores\n",
       "aboutaggregations.0.about                                        None\n",
       "aggregations.0.edmDataProvider.def                            Pattaya\n",
       "aggregations.0.edmProvider.def                                DISMARC\n",
       "aggregations.0.edmRights.def            http://www.europeana.eu/ri...\n",
       "aggregations.0.webResources.0.about     http://econnect.ait.co.at/...\n",
       "aggregations.0.edmIsShownBy             http://econnect.ait.co.at/...\n",
       "proxies.0.dctermsCreated.def                                     None\n",
       "proxies.0.dctermsExtent.def             00:03:33, 00:00:30 (previe...\n",
       "proxies.0.dctermsMedium.def                                      None\n",
       "proxies.0.dctermsSpatial.def                                     None\n",
       "proxies.0.dctermsTOC.def                                         None\n",
       "proxies.0.dctermsIsPartOf.def                       PATY/884385556396\n",
       "proxies.0.dcFormat.def                                           None\n",
       "proxies.0.dcCoverage.def                                         None\n",
       "proxies.0.dcContributor.def             Alberto Morán (Performer),...\n",
       "proxies.0.dcCreator.def                                          None\n",
       "proxies.0.dcSubject.def                 Art > World music, Popular...\n",
       "proxies.0.dcLanguage.def                                          mul\n",
       "proxies.0.dcDescription.def                                      None\n",
       "proxies.0.dcType.def                                            Sound\n",
       "proxies.0.dcSource.def                  The Orchard, http://www.th...\n",
       "proxies.0.dcRights.def                        2006 Lantower Argentina\n",
       "europeanaAggregation.edmCountry.def                            europe\n",
       "europeanaAggregation.edmLanguage.def                              mul\n",
       "europeanaCollectionName                         2023601_Ag_DE_DISMARC\n",
       "index_librosa                                                  232623\n",
       "Name: /2023601/oai_eu_dismarc_PATY_ART340900331, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.ix[221100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:31.077000",
     "start_time": "2016-11-02T11:12:30.766000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = (((((\n",
    "(md[\"proxies.0.dcCreator.def\"] + \" \")\n",
    ".str.cat(md[\"proxies.0.dcContributor.def\"]) + \" \")\n",
    ".str.cat(md[\"title\"]) + \" \")\n",
    ".str.cat(md[\"proxies.0.dcDescription.def\"]) + \" \")\n",
    ".str.cat(md[\"proxies.0.dctermsSpatial.def\"]) + \" \")\n",
    ".str.cat(md[\"proxies.0.dcSubject.def\"])\n",
    ".str.strip()).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:31.081000",
     "start_time": "2016-11-02T11:12:31.079000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"G:/eu_sounds_challenge/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-11-11T13:42:58.154Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read csv-data (separated by semicolons)\n",
    "metadata = pd.read_csv(\"E:/Features/MIR/EuropeanaSounds/metadata/metadata.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# convert nan-values to empty strings\n",
    "metadata = metadata.fillna(\"\")\n",
    "\n",
    "# use the \"id\" field as index\n",
    "metadata = metadata.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:31.537000",
     "start_time": "2016-11-02T11:12:31.534000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata[\"genre\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:31.557000",
     "start_time": "2016-11-02T11:12:31.539000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contributor     Šmits, Herberts, Vētra, Mariss, 1901-1965\n",
       "country                                            latvia\n",
       "created                                                  \n",
       "creator                                                  \n",
       "dataProvider                   National Library of Latvia\n",
       "date                                               [1935]\n",
       "description                                              \n",
       "format             Shellac record, audio/mpeg, image/jpeg\n",
       "identifier                                           2623\n",
       "language                                                 \n",
       "medium                                         audio disc\n",
       "provider                                 Europeana Sounds\n",
       "publisher                              Latvija : Homophon\n",
       "relation                                                 \n",
       "spatial                                                  \n",
       "subject                           Popular music -- Latvia\n",
       "title                           Vecais ratiņš : slov-foks\n",
       "type                                                     \n",
       "year                                                     \n",
       "genre                                                    \n",
       "Name: /2059201/data_sounds_55236, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 50)\n",
    "metadata.ix[1110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:31.798000",
     "start_time": "2016-11-02T11:12:31.559000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = ((((((\n",
    "(metadata.genre + \" \")\n",
    ".str.cat(metadata.creator) + \" \")\n",
    ".str.cat(metadata.contributor) + \" \")\n",
    ".str.cat(metadata.title) + \" \")\n",
    ".str.cat(metadata.description) + \" \")\n",
    ".str.cat(metadata.subject) + \" \")\n",
    ".str.cat(metadata.country)\n",
    ".str.strip()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:12:31.827000",
     "start_time": "2016-11-02T11:12:31.800000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "stop_words.extend(get_stop_words('en'))\n",
    "stop_words.extend(get_stop_words('de'))\n",
    "stop_words.extend(get_stop_words('fr'))\n",
    "stop_words.extend(get_stop_words('it'))\n",
    "stop_words.extend(get_stop_words('pt'))\n",
    "stop_words.extend(get_stop_words('ro'))\n",
    "stop_words.extend(get_stop_words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:13:50.006000",
     "start_time": "2016-11-02T11:12:31.829000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "texts = [[unicodedata.normalize('NFKD', word).encode('ASCII', 'ignore') \n",
    "              for word in tokenizer.tokenize(document.lower()) \n",
    "                  if (word not in stop_words and len(word) > 1)] for document in documents if len(document) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T11:13:50.731000",
     "start_time": "2016-11-02T11:13:50.007000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if (frequency[token] > 1)]\n",
    "         for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:35:27.728000",
     "start_time": "2016-10-19T14:35:27.724000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[220200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:35:01.826000",
     "start_time": "2016-10-19T14:35:01.823000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312096"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:34:36.466000",
     "start_time": "2016-10-19T14:34:36.443000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-491-d45437b724b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m22000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\" \".join(texts[22000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:12:24.273000",
     "start_time": "2016-10-19T14:12:24.250000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.317685321551302"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(texts[i]) for i in range(len(texts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:12:41.805000",
     "start_time": "2016-10-19T14:12:24.275000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-19 14:12:24,276 : INFO : collecting all words and their counts\n",
      "2016-10-19 14:12:24,278 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2016-10-19 14:12:24,322 : INFO : PROGRESS: at sentence #10000, processed 305429 words, keeping 7972 word types\n",
      "2016-10-19 14:12:24,367 : INFO : PROGRESS: at sentence #20000, processed 620071 words, keeping 12477 word types\n",
      "2016-10-19 14:12:24,479 : INFO : PROGRESS: at sentence #30000, processed 1312027 words, keeping 39732 word types\n",
      "2016-10-19 14:12:24,496 : INFO : collected 40226 word types from a corpus of 1411810 raw words and 32592 sentences\n",
      "2016-10-19 14:12:24,565 : INFO : min_count=5 retains 19368 unique words (drops 20858)\n",
      "2016-10-19 14:12:24,566 : INFO : min_count leaves 1357258 word corpus (96% of original 1411810)\n",
      "2016-10-19 14:12:24,644 : INFO : deleting the raw counts dictionary of 40226 items\n",
      "2016-10-19 14:12:24,647 : INFO : sample=0.001 downsamples 30 most-common words\n",
      "2016-10-19 14:12:24,647 : INFO : downsampling leaves estimated 1093058 word corpus (80.5% of prior 1357258)\n",
      "2016-10-19 14:12:24,648 : INFO : estimated required memory for 19368 words and 1000 dimensions: 164628000 bytes\n",
      "2016-10-19 14:12:24,703 : INFO : resetting layer weights\n",
      "2016-10-19 14:12:25,420 : INFO : training model with 4 workers on 19368 vocabulary and 1000 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2016-10-19 14:12:25,421 : INFO : expecting 32592 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-10-19 14:12:26,448 : INFO : PROGRESS: at 11.23% examples, 312651 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 14:12:27,473 : INFO : PROGRESS: at 13.77% examples, 315500 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 14:12:28,473 : INFO : PROGRESS: at 17.44% examples, 317363 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 14:12:29,486 : INFO : PROGRESS: at 27.93% examples, 327287 words/s, in_qsize 6, out_qsize 0\n",
      "2016-10-19 14:12:30,497 : INFO : PROGRESS: at 33.06% examples, 323544 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 14:12:31,542 : INFO : PROGRESS: at 35.40% examples, 324712 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 14:12:32,536 : INFO : PROGRESS: at 44.42% examples, 327740 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 14:12:33,581 : INFO : PROGRESS: at 52.89% examples, 328529 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 14:12:34,622 : INFO : PROGRESS: at 54.82% examples, 327909 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 14:12:35,624 : INFO : PROGRESS: at 63.01% examples, 330469 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 14:12:36,644 : INFO : PROGRESS: at 72.70% examples, 330970 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 14:12:37,644 : INFO : PROGRESS: at 74.62% examples, 331427 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 14:12:38,671 : INFO : PROGRESS: at 81.22% examples, 332166 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 14:12:39,744 : INFO : PROGRESS: at 92.17% examples, 332535 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 14:12:40,763 : INFO : PROGRESS: at 94.41% examples, 332424 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 14:12:41,767 : INFO : PROGRESS: at 99.43% examples, 333017 words/s, in_qsize 3, out_qsize 1\n",
      "2016-10-19 14:12:41,769 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-10-19 14:12:41,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-10-19 14:12:41,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-10-19 14:12:41,802 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-10-19 14:12:41,803 : INFO : training on 7059050 raw words (5465602 effective words) took 16.4s, 333685 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(texts, size=1000, window=10, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:17:02.835000",
     "start_time": "2016-10-18T17:17:02.832000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98782684219615091"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"mozart\", \"amadeus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:17:02.853000",
     "start_time": "2016-10-18T17:17:02.837000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76947588192284821"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_similarity([\"chopin\",\"offenbach\"],[\"classic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:36:07.284000",
     "start_time": "2016-10-19T14:36:07.251000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('core', 0.9724166393280029),\n",
       " ('alice', 0.9718669652938843),\n",
       " ('pacini', 0.9699550867080688),\n",
       " ('htb', 0.9669064283370972),\n",
       " ('mazzoleni', 0.9667044878005981),\n",
       " ('scarlatti', 0.9662805795669556),\n",
       " ('clavicorde', 0.9662434458732605),\n",
       " ('vlc', 0.9657636284828186),\n",
       " ('caruso', 0.965447723865509),\n",
       " ('giovanni', 0.9652591943740845),\n",
       " ('fl', 0.9651468396186829),\n",
       " ('lombardi', 0.9647630453109741),\n",
       " ('alma', 0.9643343687057495),\n",
       " ('castellazzi', 0.9630222320556641),\n",
       " ('arioso', 0.9626851081848145),\n",
       " ('pagliacci', 0.9626724720001221),\n",
       " ('gurlitt', 0.9615856409072876),\n",
       " ('torna', 0.9615195989608765),\n",
       " ('prelude', 0.9615018367767334),\n",
       " ('prologo', 0.9613460898399353),\n",
       " ('basson', 0.9613147974014282),\n",
       " ('bodky', 0.9596811532974243),\n",
       " ('strofe', 0.9595828652381897),\n",
       " ('seville', 0.9594621658325195),\n",
       " ('mattia', 0.9594092965126038),\n",
       " ('vidi', 0.9592790007591248),\n",
       " ('gluck', 0.9583433866500854),\n",
       " ('arr', 0.9575711488723755),\n",
       " ('russ', 0.9575594663619995),\n",
       " ('concerto', 0.9573565721511841)]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([\"majeur\", \"major\", \"andante\", \"allegro\", \"sonata\", \"fugue\", \"sonate\", \"compositeur\"], \n",
    "                   [\"singer\", \"arrangeur\"],\n",
    "                   topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:13:25.541000",
     "start_time": "2016-10-19T14:13:25.507000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('castellazzi', 0.9378741979598999),\n",
       " ('caruso', 0.9192914366722107),\n",
       " ('giovanni', 0.9192336797714233),\n",
       " ('patti', 0.9189188480377197),\n",
       " ('gluck', 0.9147874116897583),\n",
       " ('arioso', 0.9143836498260498),\n",
       " ('htb', 0.9141067862510681),\n",
       " ('adelina', 0.9128225445747375),\n",
       " ('bodky', 0.9102062582969666),\n",
       " ('ulysses', 0.9095026850700378),\n",
       " ('terra', 0.9091941118240356),\n",
       " ('alice', 0.9085679650306702),\n",
       " ('terzetto', 0.9083512425422668),\n",
       " ('johan', 0.9078710675239563),\n",
       " ('zenatello', 0.9078000783920288),\n",
       " ('strofe', 0.9076767563819885),\n",
       " ('russ', 0.905815601348877),\n",
       " ('pacini', 0.9050401449203491),\n",
       " ('mefistofele', 0.9033681154251099),\n",
       " ('cavatina', 0.9033201336860657),\n",
       " ('giannina', 0.9023322463035583),\n",
       " ('core', 0.9014116525650024),\n",
       " ('soave', 0.9009794592857361),\n",
       " ('gurlitt', 0.8999053835868835),\n",
       " ('fl', 0.8995052576065063),\n",
       " ('lombardi', 0.898522675037384),\n",
       " ('vidi', 0.8971827626228333),\n",
       " ('rossini', 0.8966554999351501),\n",
       " ('prologo', 0.8937667012214661),\n",
       " ('parsi', 0.8925209045410156)]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar_cosmul([\"concerto\", \"prelude\", \"duett\", \"fugue\"], \n",
    "                          [], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T14:40:32.055000",
     "start_time": "2016-10-19T14:40:31.852000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1791', 0.8946651220321655),\n",
       " ('1756', 0.8765036463737488),\n",
       " ('1759', 0.8638619780540466),\n",
       " ('1685', 0.8564209342002869),\n",
       " ('christoph', 0.8558024764060974),\n",
       " ('gaetano', 0.837415874004364),\n",
       " ('1843', 0.8364599347114563),\n",
       " ('1714', 0.8359813094139099),\n",
       " ('alda', 0.8348263502120972),\n",
       " ('willibald', 0.8292129039764404),\n",
       " ('giuseppe', 0.8281602263450623),\n",
       " ('carl', 0.8261173963546753),\n",
       " ('1801', 0.8252905011177063),\n",
       " ('1886', 0.8222440481185913),\n",
       " ('schubert', 0.8219956755638123),\n",
       " ('sebastian', 0.8212117552757263),\n",
       " ('gustav', 0.8193891644477844),\n",
       " ('1896', 0.8149348497390747),\n",
       " ('stransky', 0.810939371585846),\n",
       " ('gioachino', 0.810754656791687)]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar_cosmul(positive=[\"wolfgang\", \"amadeus\", \"mozart\",\n",
    "                                    \"friedrich\", \"handel\", \n",
    "                                    \"compositeur\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T13:44:31.607000",
     "start_time": "2016-10-19T13:44:31.594000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giuseppe 0.919923424721\n",
      "av 0.916781008244\n",
      "giacomo 0.913340687752\n",
      "van 0.912716984749\n",
      "vincenzo 0.91206240654\n",
      "gentil 0.909741520882\n",
      "xavier 0.906051695347\n",
      "faust 0.904570698738\n",
      "luisa 0.897276759148\n",
      "franz 0.897090554237\n",
      "iv 0.895191133022\n",
      "lucia 0.892682552338\n",
      "deh 0.88970053196\n",
      "strauss 0.889042615891\n",
      "vieni 0.888922393322\n",
      "med 0.886771559715\n",
      "orchester 0.886404752731\n",
      "rockstroh 0.884919524193\n",
      "gaetano 0.884215593338\n",
      "freischutz 0.883634269238\n"
     ]
    }
   ],
   "source": [
    "for x in model.most_similar(positive=[\"composer\", \"compositeur\", \"smetana\", \"bach\", \"beethoven\", \"handel\", \"wagner\", \"verdi\", \"rossini\"],\n",
    "                            negative=[\"lyricist\", \"singer\", \"instrumentalist\", \"arranger\", \"informateur\", \"flute\"],\n",
    "                            topn=20):\n",
    "    print x[0], x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T15:23:41.441000",
     "start_time": "2016-10-18T15:23:41.438000"
    },
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19367\n"
     ]
    }
   ],
   "source": [
    "print len(model.vocab)\n",
    "#model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T13:44:55.910000",
     "start_time": "2016-10-19T13:44:50.094000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-19 13:44:50,095 : INFO : collecting all words and their counts\n",
      "2016-10-19 13:44:50,096 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2016-10-19 13:44:51,177 : INFO : PROGRESS: at sentence #10000, processed 282265 words and 34314 word types\n",
      "2016-10-19 13:44:52,437 : INFO : PROGRESS: at sentence #20000, processed 578896 words and 64822 word types\n",
      "2016-10-19 13:44:55,247 : INFO : PROGRESS: at sentence #30000, processed 1230777 words and 396403 word types\n",
      "2016-10-19 13:44:55,637 : INFO : collected 414253 word types from a corpus of 1320847 words (unigram + bigrams) and 32592 sentences\n",
      "2016-10-19 13:44:55,638 : INFO : merging 414253 counts into Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2016-10-19 13:44:55,871 : INFO : merged Phrases<414253 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T13:44:55.915000",
     "start_time": "2016-10-19T13:44:55.912000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'schorr', u'lyricist', u'burstein_peisach', u'singer', u'secunda', u'composer', u'voice_solo', u'france']\n"
     ]
    }
   ],
   "source": [
    "print(bigram[texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T13:45:26.055000",
     "start_time": "2016-10-19T13:45:16.748000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_bigram = [bigram[text] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T13:46:18.337000",
     "start_time": "2016-10-19T13:46:02.095000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-19 13:46:02,096 : INFO : collecting all words and their counts\n",
      "2016-10-19 13:46:02,098 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2016-10-19 13:46:02,142 : INFO : PROGRESS: at sentence #10000, processed 209584 words, keeping 8731 word types\n",
      "2016-10-19 13:46:02,193 : INFO : PROGRESS: at sentence #20000, processed 399440 words, keeping 16134 word types\n",
      "2016-10-19 13:46:02,334 : INFO : PROGRESS: at sentence #30000, processed 936763 words, keeping 48676 word types\n",
      "2016-10-19 13:46:02,354 : INFO : collected 49575 word types from a corpus of 1004625 raw words and 32592 sentences\n",
      "2016-10-19 13:46:02,444 : INFO : min_count=5 retains 25881 unique words (drops 23694)\n",
      "2016-10-19 13:46:02,446 : INFO : min_count leaves 943225 word corpus (93% of original 1004625)\n",
      "2016-10-19 13:46:02,551 : INFO : deleting the raw counts dictionary of 49575 items\n",
      "2016-10-19 13:46:02,552 : INFO : sample=0.001 downsamples 25 most-common words\n",
      "2016-10-19 13:46:02,553 : INFO : downsampling leaves estimated 762540 word corpus (80.8% of prior 943225)\n",
      "2016-10-19 13:46:02,555 : INFO : estimated required memory for 25881 words and 1000 dimensions: 219988500 bytes\n",
      "2016-10-19 13:46:02,634 : INFO : resetting layer weights\n",
      "2016-10-19 13:46:03,605 : INFO : training model with 4 workers on 25881 vocabulary and 1000 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2016-10-19 13:46:03,605 : INFO : expecting 32592 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-10-19 13:46:04,618 : INFO : PROGRESS: at 12.69% examples, 268741 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 13:46:05,707 : INFO : PROGRESS: at 14.48% examples, 244755 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:06,713 : INFO : PROGRESS: at 22.15% examples, 257126 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:07,747 : INFO : PROGRESS: at 32.85% examples, 260658 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:08,763 : INFO : PROGRESS: at 34.65% examples, 254653 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:09,776 : INFO : PROGRESS: at 43.15% examples, 256839 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:10,829 : INFO : PROGRESS: at 52.95% examples, 259773 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:11,828 : INFO : PROGRESS: at 54.77% examples, 255533 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:12,834 : INFO : PROGRESS: at 65.87% examples, 260168 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 13:46:13,835 : INFO : PROGRESS: at 73.18% examples, 260922 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:14,871 : INFO : PROGRESS: at 75.01% examples, 258142 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 13:46:15,921 : INFO : PROGRESS: at 88.35% examples, 260285 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:16,960 : INFO : PROGRESS: at 93.35% examples, 259063 words/s, in_qsize 7, out_qsize 0\n",
      "2016-10-19 13:46:17,980 : INFO : PROGRESS: at 96.73% examples, 258462 words/s, in_qsize 8, out_qsize 0\n",
      "2016-10-19 13:46:18,265 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-10-19 13:46:18,266 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-10-19 13:46:18,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-10-19 13:46:18,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-10-19 13:46:18,299 : INFO : training on 5023125 raw words (3812221 effective words) took 14.7s, 259515 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model_bigram = gensim.models.Word2Vec(texts_bigram, size=1000, window=20, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T15:24:02.147000",
     "start_time": "2016-10-18T15:24:02.109000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>orchestre_mozart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14492</th>\n",
       "      <td>academica_mozarteum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15263</th>\n",
       "      <td>mozart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17532</th>\n",
       "      <td>mozart_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21108</th>\n",
       "      <td>mozart_wolfgang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21778</th>\n",
       "      <td>divertissement_mozart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "9186        orchestre_mozart\n",
       "14492    academica_mozarteum\n",
       "15263                 mozart\n",
       "17532            mozart_comp\n",
       "21108        mozart_wolfgang\n",
       "21778  divertissement_mozart"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(model_bigram.vocab))\n",
    "df[df[0].str.contains(\"mozart\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T13:46:30.061000",
     "start_time": "2016-10-19T13:46:29.893000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-19 13:46:29,895 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joe_cooley 0.978929936886\n",
      "mrs 0.976350128651\n",
      "unidentified 0.974154114723\n",
      "harrison 0.973539113998\n",
      "frank_quinn 0.970666527748\n",
      "unidentified_piano 0.969449281693\n",
      "william_mullaly 0.968471765518\n",
      "concert_hall 0.967836141586\n",
      "guitar_instrumentalist 0.967309653759\n",
      "island 0.966392278671\n",
      "market 0.966380953789\n",
      "kesh 0.965722203255\n",
      "micheal 0.965506672859\n",
      "tenpenny 0.965464949608\n",
      "tim 0.96447789669\n",
      "fiddle_unidentified 0.964016854763\n",
      "lisdoon 0.963634133339\n",
      "murty_rabbett 0.963227391243\n",
      "seoighe 0.962851941586\n",
      "newly_mown 0.962595105171\n"
     ]
    }
   ],
   "source": [
    "for x in model_bigram.most_similar(positive=[\"irish\", \"folk\", \"ireland\", \"irish_traditional\", \"flogging_tune\", \"sheridan\", \n",
    "                                             \"lough_erne\", \"herbert_hughes\", \"seamus\"], \n",
    "                                   #negative=[\"flamenco\",\"paris\",\"french\", \"ukrainian\"], \n",
    "                                   topn=20):\n",
    "    print x[0], x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-19T13:51:58.987000",
     "start_time": "2016-10-19T13:51:58.975000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friedrich_compositeur 0.997922480106\n",
      "handel_georg 0.996378064156\n",
      "sharpe 0.995897531509\n",
      "boulanger_ensemble 0.995296239853\n",
      "sv 0.994497299194\n",
      "gavotte 0.99421620369\n",
      "orch_comprend 0.994091629982\n",
      "rameau_comp 0.993809700012\n",
      "donateur_anonyme 0.992979943752\n",
      "compositeur_rouget 0.992966294289\n",
      "nadia_boulanger 0.992602467537\n",
      "mozart_comp 0.992157936096\n",
      "pascal_seguin 0.992108225822\n",
      "generosite 0.991973340511\n",
      "arr 0.991805076599\n",
      "soliste_france 0.991728007793\n",
      "orchestre_comprend 0.991655170918\n",
      "soprano 0.991555035114\n",
      "meistersinger 0.991267800331\n",
      "ensemble_nadia 0.99123442173\n"
     ]
    }
   ],
   "source": [
    "for x in model_bigram.most_similar(positive=[\"beethoven\", \"compositeur\"], \n",
    "                                   #negative=[\"sharpe\", \"soprano\"], \n",
    "                                   topn=20):\n",
    "    print x[0], x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "documents = ((((\n",
    "(metadata.contributor + \" \")\n",
    ".str.cat(metadata.title) + \" \")\n",
    ".str.cat(metadata.description) + \" \")\n",
    ".str.cat(metadata.subject) + \" \")\n",
    ".str.cat(metadata.country)\n",
    ".str.strip()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"smetana\", \"bach\", \"beethoven\", \"handel\", \"wagner\", \"verdi\", \"rossini\", \"mozart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:14:57.281000",
     "start_time": "2016-10-18T17:14:56.985000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 300)\n",
    "search = \"moynagh\"\n",
    "\n",
    "metadata[\n",
    "metadata[\"contributor\"].str.lower().str.contains(search) | \n",
    "metadata[\"creator\"].str.lower().str.contains(search) |\n",
    "metadata[\"title\"].str.lower().str.contains(search) |\n",
    "metadata[\"subject\"].str.lower().str.contains(search) |\n",
    "metadata[\"description\"].str.lower().str.contains(search) \n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T17:14:59.304000",
     "start_time": "2016-10-18T17:14:59.158000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata.loc[\n",
    "metadata[\"contributor\"].str.lower().str.contains(search) | \n",
    "metadata[\"creator\"].str.lower().str.contains(search) |\n",
    "metadata[\"title\"].str.lower().str.contains(search),\n",
    "\"genre\"] = \"irish_folk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T16:28:45.616000",
     "start_time": "2016-10-18T16:28:45.407000"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "sr[\"genre\"] = \"classic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-18T16:10:50.031000",
     "start_time": "2016-10-18T16:09:09.740000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-18 16:10:29,263 : INFO : collecting all words and their counts\n",
      "2016-10-18 16:10:29,263 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2016-10-18 16:10:30,394 : INFO : PROGRESS: at sentence #10000, processed 295344 words and 37796 word types\n",
      "2016-10-18 16:10:31,713 : INFO : PROGRESS: at sentence #20000, processed 599965 words and 68838 word types\n",
      "2016-10-18 16:10:34,723 : INFO : PROGRESS: at sentence #30000, processed 1281532 words and 410083 word types\n",
      "2016-10-18 16:10:35,194 : INFO : collected 428645 word types from a corpus of 1378521 words (unigram + bigrams) and 32592 sentences\n",
      "2016-10-18 16:10:35,194 : INFO : merging 428645 counts into Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2016-10-18 16:10:35,463 : INFO : merged Phrases<428645 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2016-10-18 16:10:45,573 : INFO : collecting all words and their counts\n",
      "2016-10-18 16:10:45,575 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2016-10-18 16:10:45,621 : INFO : PROGRESS: at sentence #10000, processed 217980 words, keeping 9641 word types\n",
      "2016-10-18 16:10:45,674 : INFO : PROGRESS: at sentence #20000, processed 412627 words, keeping 17279 word types\n",
      "2016-10-18 16:10:45,816 : INFO : PROGRESS: at sentence #30000, processed 968040 words, keeping 50699 word types\n",
      "2016-10-18 16:10:45,838 : INFO : collected 51673 word types from a corpus of 1040428 raw words and 32592 sentences\n",
      "2016-10-18 16:10:45,931 : INFO : min_count=5 retains 27339 unique words (drops 24334)\n",
      "2016-10-18 16:10:45,931 : INFO : min_count leaves 977348 word corpus (93% of original 1040428)\n",
      "2016-10-18 16:10:46,042 : INFO : deleting the raw counts dictionary of 51673 items\n",
      "2016-10-18 16:10:46,045 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2016-10-18 16:10:46,045 : INFO : downsampling leaves estimated 799075 word corpus (81.8% of prior 977348)\n",
      "2016-10-18 16:10:46,046 : INFO : estimated required memory for 27339 words and 100 dimensions: 35540700 bytes\n",
      "2016-10-18 16:10:46,131 : INFO : resetting layer weights\n",
      "2016-10-18 16:10:46,696 : INFO : training model with 4 workers on 27339 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2016-10-18 16:10:46,697 : INFO : expecting 32592 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-10-18 16:10:47,709 : INFO : PROGRESS: at 33.00% examples, 1169254 words/s, in_qsize 5, out_qsize 0\n",
      "2016-10-18 16:10:48,706 : INFO : PROGRESS: at 59.21% examples, 1184140 words/s, in_qsize 0, out_qsize 1\n",
      "2016-10-18 16:10:49,710 : INFO : PROGRESS: at 93.25% examples, 1196709 words/s, in_qsize 0, out_qsize 0\n",
      "2016-10-18 16:10:50,006 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-10-18 16:10:50,009 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-10-18 16:10:50,012 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-10-18 16:10:50,015 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-10-18 16:10:50,015 : INFO : training on 5202140 raw words (3995788 effective words) took 3.3s, 1204916 effective words/s\n"
     ]
    }
   ],
   "source": [
    "expanded_documents = [line.lower().replace(\"comp.\", \"composer\").replace(\"compositeur\", \"composer\") for line in documents]\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "texts = [[unicodedata.normalize('NFKD', word).encode('ASCII', 'ignore') for word in tokenizer.tokenize(document.lower()) if (word not in stop_words and len(word) > 1)] for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "\n",
    "bigram = gensim.models.Phrases(texts)\n",
    "\n",
    "texts_bigram = [bigram[text] for text in texts]\n",
    "model_bigram = gensim.models.Word2Vec(texts_bigram, size=100, window=5, min_count=5, workers=4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "notify_time": "5",
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
