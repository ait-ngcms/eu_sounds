{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Work/IFS/rp_extract\")\n",
    "\n",
    "import librosa \n",
    "\n",
    "os.environ['PATH'] += os.pathsep + \"D:/Research/Tools/ffmpeg/bin\"\n",
    "\n",
    "import audiofile_read as ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR    = \"E:/Data/MIR/EU_SOUNDS\"\n",
    "FEATURE_DIR = \"E:/Data/MIR/EU_SOUNDS_FEATURES_LIBROSA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"chroma\"] = lambda S, sr : \\\n",
    "\\\n",
    "        librosa.feature.chroma_stft(S          = S   ,         # power spectrogram\n",
    "                                    sr         = sr,           # samplerate\n",
    "                                    norm       = np.inf,       # Column-wise normalization\n",
    "                                    tuning     = None)         # Deviation from A440 tuning in fractional bins (cents). \n",
    "                                                               #    If None, it is automatically estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"mfcc\"] = lambda S, sr : \\\n",
    "\\\n",
    "        librosa.feature.mfcc(S      = S,                       # power spectrogram\n",
    "                             sr     = sr,                      # samplerate\n",
    "                             n_mfcc = 13)                      # number of MFCCs to return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"rmse\"] = lambda S, sr : \\\n",
    "\\\n",
    "        librosa.feature.rmse(S  = S)                           # power spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"spectral_centroid\"] = lambda S, sr : \\\n",
    "\\\n",
    "        librosa.feature.spectral_centroid(S  = S,              # power spectrogram\n",
    "                                          sr = sr)             # samplerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"spectral_bandwidth\"] = lambda S, sr : \\\n",
    "\\\n",
    "        librosa.feature.spectral_bandwidth(S  = S,             # power spectrogram\n",
    "                                           sr = sr)            # samplerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"spectral_contrast\"] = lambda S, sr : \\\n",
    "\\\n",
    "        librosa.feature.spectral_contrast(sr         = sr,     # sampling rate of y\n",
    "                                          S          = S,      # power spectrogram\n",
    "                                          freq       = None,   # Center frequencies for spectrogram bins. If None, then \n",
    "                                                               #   FFT bin center frequencies are used. Otherwise, it \n",
    "                                                               #   can be a single array of d center frequencies, or \n",
    "                                                               #   a matrix of center frequencies as constructed by \n",
    "                                                               #   librosa.core.ifgram, centroid=None, norm=True, p=2)\n",
    "                                          fmin       = 200.0,  # Frequency cutoff for the first bin [0, fmin] Subsequent\n",
    "                                                               #   bins will cover [fmin, 2*fmin], [2*fmin, 4*fmin], etc.\n",
    "                                          n_bands    = 6,      # number of frequency bands\n",
    "                                          quantile   = 0.02,   # quantile for determining peaks and valleys\n",
    "                                          linear     = False)  # If True, return the linear difference of magnitudes: \n",
    "                                                               #   peaks - valleys.\n",
    "                                                               # If False, return the logarithmic difference: \n",
    "                                                               #   log(peaks) - log(valleys)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Rolloff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"spectral_rolloff\"] = lambda S, sr : \\\n",
    "\\\n",
    "        librosa.feature.spectral_rolloff(sr           = sr,     # sampling rate of y\n",
    "                                         S            = S,      # power spectrogram\n",
    "                                         freq         = None,   # Center frequencies for spectrogram bins. If None, then \n",
    "                                                                #   FFT bin center frequencies are used. Otherwise, it \n",
    "                                                                #   can be a single array of d center frequencies, or \n",
    "                                                                #   a matrix of center frequencies as constructed by \n",
    "                                                                #   librosa.core.ifgram, centroid=None, norm=True, p=2)\n",
    "                                         roll_percent = 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"tonnetz\"] = lambda chroma, sr : \\\n",
    "\\\n",
    "        librosa.feature.tonnetz(sr     = sr,                    # sampling rate of y\n",
    "                                chroma = chroma)                # Normalized energy for each chroma bin at each frame.\n",
    "                                                                #   If None, a cqt chromagram is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor[\"zero_crossing_rate\"] = lambda y : \\\n",
    "\\\n",
    "        librosa.feature.zero_crossing_rate(y            = y,    # audio time series\n",
    "                                           frame_length = 2048, # Length of the frame over which to compute \n",
    "                                                                # zero crossing rates\n",
    "                                           hop_length   = 512,  # hop length if provided y, sr instead of S\n",
    "                                           center       = True) # If True, frames are centered by padding the edges of y. \n",
    "                                                                #   This is similar to the padding in librosa.core.stft, \n",
    "                                                                #   but uses edge-value copies instead of reflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spectral_bandwidth',\n",
       " 'rmse',\n",
       " 'spectral_rolloff',\n",
       " 'mfcc',\n",
       " 'chroma',\n",
       " 'spectral_contrast',\n",
       " 'tonnetz',\n",
       " 'spectral_centroid',\n",
       " 'zero_crossing_rate']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beats per Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_bpm(S, sr, audio_length):\n",
    "             \n",
    "    onset_env = librosa.onset.onset_strength(S         = S,     # pre-computed (log-power) spectrogram\n",
    "                                             detrend   = False, # Filter the onset strength to remove the DC component\n",
    "                                             centering = True,  # Shift the onset function by n_fft / (2 * hop_length) frames\n",
    "                                             feature   = None,  # Function for computing time-series features, eg, scaled\n",
    "                                                                #   spectrograms. By default, uses \n",
    "                                                                #   librosa.feature.melspectrogram with fmax=8000.0\n",
    "                                             aggregate = None)  # Aggregation function to use when combining onsets at \n",
    "                                                                #   different frequency bins.Default: np.mean\n",
    "    \n",
    "    \n",
    "    if audio_length > 60:\n",
    "        duration = 40.0\n",
    "        offset   = 10.0\n",
    "    else:\n",
    "        duration = audio_length\n",
    "        offset   = 0.0\n",
    "                          \n",
    "             \n",
    "    bpm = librosa.beat.estimate_tempo(onset_env,                # onset_envelope : onset strength envelope\n",
    "                                      sr         = sr,          # sampling rate of the time series\n",
    "                                      start_bpm  = 120,         # initial guess of the BPM\n",
    "                                      std_bpm    = 1.0,         # standard deviation of tempo distribution\n",
    "                                      ac_size    = 4.0,         # length (in seconds) of the auto-correlation window\n",
    "                                      duration   = duration,    # length of signal (in seconds) to use in estimating tempo\n",
    "                                      offset     = offset)      # offset (in seconds) of signal sample to use in estimating\n",
    "                                                                # tempo\n",
    "             \n",
    "    return bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_librosa_features(wavedata, samplerate, dest_path):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # merge audio channels\n",
    "        wavedata           = wavedata.mean(axis=1)\n",
    "        \n",
    "        # calculate spectrogram\n",
    "        spectrogram, phase = librosa.magphase(librosa.stft(wavedata, n_fft = 2048))\n",
    "\n",
    "        # extract features\n",
    "        chroma             = feature_extractor[\"chroma\"](spectrogram, samplerate)\n",
    "        mfcc               = feature_extractor[\"mfcc\"](spectrogram, samplerate)\n",
    "        rmse               = feature_extractor[\"rmse\"](spectrogram, samplerate)\n",
    "        spectral_centroid  = feature_extractor[\"spectral_centroid\"](spectrogram, samplerate)\n",
    "        spectral_bandwidth = feature_extractor[\"spectral_bandwidth\"](spectrogram, samplerate)\n",
    "        spectral_contrast  = feature_extractor[\"spectral_contrast\"](spectrogram, samplerate)\n",
    "        spectral_rolloff   = feature_extractor[\"spectral_rolloff\"](spectrogram, samplerate)\n",
    "        tonnetz            = feature_extractor[\"tonnetz\"](chroma, samplerate)\n",
    "        zero_crossing_rate = feature_extractor[\"zero_crossing_rate\"](wavedata)\n",
    "        \n",
    "        audio_length       = wavedata.shape[0] / float(samplerate)\n",
    "        bpm                = calc_bpm(spectrogram, samplerate, audio_length)\n",
    "        \n",
    "        # store data\n",
    "        np.savez(dest_path,\n",
    "                 chroma             = chroma,\n",
    "                 mfcc               = mfcc,\n",
    "                 rmse               = rmse,\n",
    "                 spectral_centroid  = spectral_centroid,\n",
    "                 spectral_bandwidth = spectral_bandwidth,\n",
    "                 spectral_contrast  = spectral_contrast,\n",
    "                 spectral_rolloff   = spectral_rolloff,\n",
    "                 tonnetz            = tonnetz,\n",
    "                 zero_crossing_rate = zero_crossing_rate,\n",
    "                 bpm                = bpm)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print \"**\", e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_files_todo = []\n",
    "\n",
    "for dir_name in glob.glob(os.path.join(DATA_DIR, \"*\")):\n",
    "    \n",
    "    src_path = dir_name.replace(\"\\\\\",\"/\")\n",
    "    dst_path = src_path.replace(DATA_DIR, FEATURE_DIR)\n",
    "    \n",
    "    if not os.path.exists(dst_path):\n",
    "        os.makedirs(dst_path)\n",
    "    \n",
    "    for mp3_name in glob.glob(os.path.join(src_path, \"*.mp3\")):\n",
    "        \n",
    "        audio_files_todo.append(mp3_name.replace(\"\\\\\",\"/\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391529"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_files_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [25150 of 391529 (0.06)]: E:/Data/MIR/EU_SOUNDS/15601/5FBC756C6C029AD667640367E835FB24D9A0BFC1.mp3\n",
      "** index 0 is out of bounds for axis 0 with size 0\n",
      "   Stored to: E:/Data/MIR/EU_SOUNDS_FEATURES_LIBROSA/15601/5FBC756C6C029AD667640367E835FB24D9A0BFC1.mp3.npz\n",
      "> [26131 of 391529 (0.07)]: E:/Data/MIR/EU_SOUNDS/2022420/cjcpctcluj_MUP_033_mp3.mp3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a519c3556b97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplewidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwavedata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmp3_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mextract_librosa_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwavedata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Work/IFS/rp_extract\\audiofile_read.pyc\u001b[0m in \u001b[0;36mmp3_read\u001b[1;34m(filename, normalize)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[0mreturn_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# subprocess.call takes a list of command + arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python_27\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36mcall\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m--> 522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python_27\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1005\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m                 _subprocess.WaitForSingleObject(self._handle,\n\u001b[1;32m-> 1007\u001b[1;33m                                                 _subprocess.INFINITE)\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_subprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetExitCodeProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "num_audio_files = len(audio_files_todo)\n",
    "\n",
    "for mp3_name in audio_files_todo:\n",
    "\n",
    "    src_filename = mp3_name.replace(\"\\\\\",\"/\")\n",
    "    dst_filename = \"%s\" % (src_filename.replace(DATA_DIR, FEATURE_DIR))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    if os.path.exists(\"%s.npz\" % (dst_filename)) or \\\n",
    "       os.path.exists(\"%s.DecoderError\" % (dst_filename)):\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    print \"> [%d of %d (%.2f)]: %s\" % (i, num_audio_files, (i / float(num_audio_files)), src_filename)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        (samplerate, samplewidth, wavedata) = ar.mp3_read(src_filename)\n",
    "\n",
    "        extract_librosa_features(wavedata, samplerate, dst_filename)\n",
    "        print \"   Stored to: %s.npz\" % (dst_filename)\n",
    "\n",
    "        del samplerate, samplewidth, wavedata\n",
    "\n",
    "\n",
    "    except ar.DecoderException as e:\n",
    "        print \"*** DecoderException\", e\n",
    "        f = open(\"%s.DecoderError\" % (dst_filename), 'w')\n",
    "        f.write(str(e))\n",
    "        f.close()\n",
    "        pass\n",
    "\n",
    "    except Exception as e:\n",
    "        print \"*** Exception\", e\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print i\n",
    "    \n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
